# Usage:
#
# LUIGI_CONFIG_PATH=client.cfg luigi ...
#
# or perhaps
#
# LUIGI_CONFIG_PATH=client.cfg luigi --local-scheduler ...

# JDBC connectivity test (for NAACCR ETL)
[HelloNAACCR]
db_url = jdbc:oracle:thin:@dbhost2:1521:database_sid
user = DB_USER
passkey = DB_PASSWORD_ENV_VARIABLE_NAME

[NAACCR_Ontology1]
db_url = jdbc:oracle:thin:@dbhost2:1521:database_sid
user = DB_USER
passkey = DB_PASSWORD
#seer_recode=,seer_recode.txt

[NAACCR_FlatFile]
flat_file=/tmp/,record0

[NAACCR_Visits]
encounter_num_start = 2000000

[NAACCR_Load]
log_dest=naaccr_load_event_log.json
db_url = jdbc:oracle:thin:@dbhost2:1521:database_sid
user = DB_USER
passkey = DB_PASSWORD
dateCaseReportExported=2001-01-01
npiRegistryId=12345678901
schema=i2b2demodata
jdbc_driver=ojdbc8.jar

[MigrateUpload]
db_url = jdbc:oracle:thin:@dbhost2:1521:database_sid
db_url_deid = jdbc:oracle:thin:@dbhost2:1521:database_sid2
user = DB_USER
passkey = DB_PASSWORD
jdbc_driver=ojdbc8.jar
schema=i2b2demodata
i2b2_deid=i2b2demodata_deid
log_dest=migrate_log.json

[spark]
# from ${SPARK_HOME}/bin/pyspark:
#
# export PYTHONPATH="${SPARK_HOME}/python/:$PYTHONPATH"
# export PYTHONPATH="${SPARK_HOME}/python/lib/py4j-0.10.4-src.zip:$PYTHONPATH"
spark-submit = .../spark-2.2.1-bin-hadoop2.7/bin/spark-submit
master = local[*]
jars = .../instantclient_11_2/ojdbc6.jar

[core]
logging_conf_file=logging.cfg
